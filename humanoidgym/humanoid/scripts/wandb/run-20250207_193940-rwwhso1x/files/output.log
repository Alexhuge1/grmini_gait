[34m[1mwandb[0m: [33mWARNING[0m Found log directory outside of given root_logdir, dropping given root_logdir for event file in /home/alexhuge/Documents/GitHub/grmini_gait/humanoidgym/logs/grmini/Feb07_19-39-34_
################################################################################
                      [1m Learning iteration 0/3001 [0m

                       Computation: 11632 steps/s (collection: 20.717s, learning 0.409s)
               Value function loss: 0.0154
                    Surrogate loss: -0.0023
             Mean action noise std: 1.00
                       Mean reward: 0.66
               Mean episode length: 49.36
Mean episode rew_action_smoothness: -0.0011
         Mean episode rew_base_acc: 0.0003
      Mean episode rew_base_height: 0.0002
        Mean episode rew_collision: -0.0001
Mean episode rew_default_joint_pos: 0.0005
          Mean episode rew_dof_acc: -0.0099
          Mean episode rew_dof_vel: -0.0103
    Mean episode rew_feet_air_time: 0.0003
   Mean episode rew_feet_clearance: 0.0007
Mean episode rew_feet_contact_forces: 0.0000
Mean episode rew_feet_contact_number: 0.0080
    Mean episode rew_feet_distance: 0.0021
        Mean episode rew_foot_slip: 0.0000
        Mean episode rew_joint_pos: 0.0017
    Mean episode rew_knee_distance: 0.0013
        Mean episode rew_low_speed: -0.0016
      Mean episode rew_orientation: 0.0047
          Mean episode rew_torques: -0.0007
   Mean episode rew_track_vel_hard: -0.0022
 Mean episode rew_tracking_ang_vel: 0.0029
 Mean episode rew_tracking_lin_vel: 0.0094
 Mean episode rew_vel_mismatch_exp: 0.0015
--------------------------------------------------------------------------------
                   Total timesteps: 245760
                    Iteration time: 21.13s
                        Total time: 21.13s
                               ETA: 63400.7s
Traceback (most recent call last):
  File "train.py", line 43, in <module>
    train(args)
  File "train.py", line 39, in train
    ppo_runner.learn(num_learning_iterations=train_cfg.runner.max_iterations, init_at_random_ep_len=True)
  File "/home/alexhuge/Documents/GitHub/grmini_gait/humanoidgym/humanoid/algo/ppo/on_policy_runner.py", line 130, in learn
    obs, privileged_obs, rewards, dones, infos = self.env.step(actions)
  File "/home/alexhuge/Documents/GitHub/grmini_gait/humanoidgym/humanoid/envs/custom/grmini_env.py", line 200, in step
    return super().step(actions)
  File "/home/alexhuge/Documents/GitHub/grmini_gait/humanoidgym/humanoid/envs/base/legged_robot.py", line 98, in step
    self.gym.simulate(self.sim)
KeyboardInterrupt
